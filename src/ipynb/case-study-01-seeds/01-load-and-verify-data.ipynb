{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Verify Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the data directly from a URL. The data is hosted in a whitespace-separated file on the UCI Machine Learning Repository. This file is available at the following URL: https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt. We first define a variable to hold this URL as a string. Note that I have named this variable using all caps. While this has no semantic meaning in Python, I have done this to signify that this string should be thought of as a constant. It is a value to be stored by the notebook that will never change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Seeds Data Set from a URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the Python Numerical Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading the libraries that comprise the Python numerical stack, including\n",
    "\n",
    "- `matplotlib`\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `seaborn`. \n",
    "\n",
    "Note that we have includes the IPython magic command `%matplotlib inline`. This will ensure that any images generated will be rendered within the notebook while we work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Entire Libraries Versus Specific Classes or Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD ALL LIBS versus adhoc with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Data Set URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCI_BASE_URL = 'https://archive.ics.uci.edu/'\n",
    "ML_REPO_URI = 'ml/machine-learning-databases/00236/seeds_dataset.txt'\n",
    "SEEDS_URL = UCI_BASE_URL + ML_REPO_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a sample of the Data Set URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtained by entering url into browser\n",
    "```\n",
    "15.26\t14.84\t0.871\t5.763\t3.312\t2.221\t5.22\t1\n",
    "14.88\t14.57\t0.8811\t5.554\t3.333\t1.018\t4.956\t1\n",
    "14.29\t14.09\t0.905\t5.291\t3.337\t2.699\t4.825\t1\n",
    "13.84\t13.94\t0.8955\t5.324\t3.379\t2.259\t4.805\t1\n",
    "16.14\t14.99\t0.9034\t5.658\t3.562\t1.355\t5.175\t1\n",
    "14.38\t14.21\t0.8951\t5.386\t3.312\t2.462\t4.956\t1\n",
    "14.69\t14.49\t0.8799\t5.563\t3.259\t3.586\t5.219\t1\n",
    "14.11\t14.1\t0.8911\t5.42\t3.302\t2.7\t\t5\t\t1\n",
    "16.63\t15.46\t0.8747\t6.053\t3.465\t2.04\t5.877\t1\n",
    "16.44\t15.25\t0.888\t5.884\t3.505\t1.969\t5.533\t1\n",
    "15.26\t14.85\t0.8696\t5.714\t3.242\t4.543\t5.314\t1\n",
    "14.03\t14.16\t0.8796\t5.438\t3.201\t1.717\t5.001\t1\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `pd.read_csv()` to load data as `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I use the `pd.read_csv()` method available as part of the Pandas library to to read the file into a `DataFrame`. A bit of special handling was required here. First, it is necessary to specify on load that the file has no header row. This is done using the argument `header=None`. Second, it is necessary to specify that this data is whitespace-separated. In other words, whitespace is used to separate the values in a row of data rather than the more conventional commas. This is done using the regular expression (regex) `\\s+`. This argument signifies that one or more whitespace character(s) should be used as separator.\n",
    "\n",
    "You can read more about regex here: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df = pd.read_csv(SEEDS_URL, header=None, sep='\\s+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually Define Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because no header row was specified it is necessary for us to manually specify the names of each column in our new `DataFrame`. These names were obtained from the attribute information section at the UCI Machine Learning Repository. Note that we have made all of the names computer-friendly by replacing whitespace with underscores.\n",
    "\n",
    "The names of the columns of a `DataFrame` are stored as the attribute `df.columns`. We can specify these names manually by assigning a list of the correct length to this attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.columns = [\n",
    "    \"area\",\n",
    "    \"perimeter\",\n",
    "    \"compactness\",\n",
    "    \"length_of_kernel\",\n",
    "    \"width_of_kernel\",\n",
    "    \"asymmetry_coefficient \",\n",
    "    \"length_of_kernel_groove\",\n",
    "    \"seed_class\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Data Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a means of verifying that the data was properly loaded, we display both the type and the shape of the `DataFrame` and the first five rows. This is done using the `type()` function, the `.shape` attribute, and the `.head()` method respectively. It is worth noting that `.shape` is an attribute and `.head()` is a method of the `Pandas.DataFrame` class, while `type()` is a Python builtin function.\n",
    "\n",
    "As expected, `seeds_df` is a Pandas `DataFrame`. It has a shape of `(210, 8)`. This corresponds to a $n = 210$ and $p=7$, plus 1 target column. Looking at the first five rows of the `DataFrame`, it appears that everything has been loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seeds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the sample we looked at above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Type Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How pandas does type casting: https://rushter.com/blog/pandas-data-type-inference/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display the defaults of `pd.read_csv()`\n",
    "\n",
    "show that in infers data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the loading process Pandas will explicitly cast each column into the most appropriate data type. Based on information available at the UCI machine learning repository page for this data set, we would expect the first seven columns to be floating-point, that is type `float`, and the eighth target column, `seed_class` to be categorical. Here we use the `.dtypes` attribute to display the data types of our `seeds_df` `DataFrame`.\n",
    "\n",
    "We note that the first seven columns have been correctly cast, but `seed_class` has been incorrectly designated as type `int`. This is no doubt due to the fact that the `seed_class` categories are encoded numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display `DataFrame.dtypes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Unique Values for the `seed_class` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `.unique()` method, we display the unique values of the `seed_class` column. Indeed, the seed classes, Kama, Rosa and Canadian, have been encoded as the numbers 1, 2, and 3. As all of the values are integers, Pandas incorrectly intuited that the column should be of type `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.seed_class.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion: Incorrect Typecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to correct this manually. We do so using the `.astype()` method. This method, applied to a column, returns a copy of that column cast into the requested data type. To complete the casting, we save this type-cast copy back as the original column.\n",
    "\n",
    "This pattern resembles this:\n",
    "\n",
    "    df.my_column = df.my_column.astype(#REQUESTEDTYPE#)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Programming Method: Transform and Reassign a Variable\n",
    "\n",
    "The programming pattern being used here is one that is fairly common. Here we take some variable, transform that variable, and then reassign the result to the original variable name. In the simplest sense, you might think about doing this with an integer\n",
    "\n",
    "    my_int = 4\n",
    "    my_int = my_int + 5\n",
    "    \n",
    "Of course, this pattern is so common that it has a shortcut that works in most popular programming languages\n",
    "\n",
    "    my_int = 4\n",
    "    my_int += 5\n",
    "    \n",
    "In general, where it is not necessary to keep incremental results of a variable, we use a pattern like this one. You might imagine doing the same in order to transform a Python `list` to a `numpy` array. \n",
    "\n",
    "    xx = [1,2,3]\n",
    "    xx = np.array(xx)\n",
    "    \n",
    "Here we have made use of the transformation and reassignment programming pattern. We cast the list `xx` as a `np.array` and reassign this to the original `np.array`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Typecasting Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cast `seed_class` as a Pandas Column of type `category`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we cast `seed_class` as the Pandas data type, category\\footnote{https://pandas.pydata.org/pandas-docs/stable/categorical.html}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.seed_class = seeds_df.seed_class.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, we display the data types of our `seeds_df` `DataFrame`. We now see that the target column, `seed_class` is now correctly encoded as categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data Set as Local Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we do not need to retrieve our data set from remote URL each time we work with it, we use the Pandas `DataFrame` methods, `.to_csv()` and `.to_pickle()`, to store local versions the downloaded file. Each of these takes a string as its argument. This string will be used as the name of the file to be saved locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Programming Method: The Python Pickle Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While you are no doubt familiar with the CSV format, this may be the first time you are learning about the Pickle format. You can read more about this format here: https://docs.python.org/3/library/pickle.html. The Pickle format is a Python specific way to save information. When you write a `DataFrame` to disk as a Pickle you can load it in later, *exactly* as it was when you saved it. Furthermore, just like Pandas as the `pd.read_csv()` method, it also includes the method `pd.read_pickle()` to help you load a Pickled `DataFrame` at some later point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.to_csv('seeds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.to_pickle('seeds.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
